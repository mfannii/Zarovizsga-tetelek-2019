\documentclass[12pt]{article}
\setlength{\textwidth}{17cm}
\setlength{\textheight}{24cm}
\setlength{\topmargin}{-2cm}
\setlength{\footskip}{1cm}
\setlength{\evensidemargin}{0cm}
\setlength{\oddsidemargin}{0cm}

\usepackage{allrunes}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fixltx2e}
\usepackage{multirow}

\usepackage[hyphens]{url}
\usepackage[unicode,colorlinks=true,breaklinks]{hyperref}
%\usepackage[dvips]{hyperref}
%should display links, but it does not work with \H accent
%and formulas in section titles

\hypersetup{colorlinks,linkcolor=blue,urlcolor=magenta,citecolor=magenta}
%Breaks long url`s in text, while keeping it one link:

\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{indentfirst}


\theoremstyle{plain}
\usepackage{graphicx}

%\usepackage{gensymb}
\usepackage{float}

% For bra-ket notation
\usepackage{braket}

%% New commands
\newcommand{\dd}{\textrm{d}}

%% Pauli matrices
\newcommand{\sigx}{\sigma_x}
\newcommand{\sigy}{\sigma_y}
\newcommand{\sigz}{\sigma_z}

\newcommand{\paulix}{
    \left( \begin{array}{cc}
        0 & 1 \\
        1 & 0
    \end{array}
    \right)
}

\newcommand{\pauliy}{
    \left( \begin{array}{cc}
        0 & -i \\
        i & 0
    \end{array}
    \right)
}

\newcommand{\pauliz}{
    \left( \begin{array}{cc}
        1 & 0 \\
        0 & -1
    \end{array}
    \right)
}


\begin{document}
\title{4th exam item}
\author{Alex Olar}

\maketitle

\newpage
\begin{abstract}
    Thermodynamic simulations, Ising-model and the Metropolis algorithm
\end{abstract}

\vspace{2mm}

\section{Introduction}

\vspace{2mm}

\par Not only do thermodynamic simulations
have important practical applications, but they also give us insight into what is “dynamic” in
thermodynamics. In the following few pages we are going
to dwelve into how to calculate thermodynamic properties of
complex systems, give a brief summary of the Metropolis algorithm and its 
applications. The theory forms the basis for field- theoretic calculations
of quantum chromodynamics, some of the most fundamental and most time-consuming
computations in existence.

\vspace{2mm}

\section{The Ising-model}

\vspace{2mm}

\par Ferromagnets contain finite-size domains in which the spins of all the atoms point in the same
direction. When an external magnetic field is applied to these materials, the different domains
align and the materials become “magnetized.” Yet as the temperature is raised, the total mag-
netism decreases, and at the Curie temperature the system goes through a phase transition
beyond which all magnetization vanishes.

\vspace{2mm}

\par To handle this behaviour we can develop the most simple model: a \textbf{chain of spins}. As our model
we consider N magnetic dipoles fixed in place on the links of a linear chain. Because
the particles are fixed, their positions and momenta are not dynamic variables, and we need
worry only about their spins. We assume that the particle at site $i$ has spin $s_{i}$ , which is either
up or down:

\vspace{2mm}

\begin{equation*}
    s_{i} \equiv s_{z, i} = \pm \frac{1}{2}
\end{equation*}

\vspace{2mm}

\par Each configuration of the N particles is described by a quantum state vector:

\vspace{2mm}

\begin{equation*}
    \ket{\alpha_{j}} = \ket{s_1, s_2, ..., s_N} = \Big\{ \pm \frac{1}{2}, \pm \frac{1}{2}, ...\Big\}, \quad j = 1, ..., 2^{N}
\end{equation*}

\vspace{2mm}

\par Since fixed particles cannot be interchanged, we do not need to concern
ourserlves with the symmtery of the wave function.

\vspace{2mm}

\par The energy of the system arises from the interaction of the spins with each other and
with the external magnetic field B . We know from quantum mechanics that an electron’s spin
and magnetic moment are proportional to each other, so a magnetic dipole–dipole interaction
is equivalent to a spin–spin interaction. We assume that each dipole interacts with the external
magnetic field and with its nearest neighbor through the potential:

\vspace{2mm}

\begin{equation*}
    V_{i} = -J\vec{s_{i}}\vec{s_{i+1}} - g\mu_{b}\vec{s_i}\vec{B}
\end{equation*}

\vspace{2mm}

\par Here the constant $J$ is called the \textit{exchange energy} and is a measure of the strength of the spin–
spin interaction. The constant $g$ is the \textit{gyromagnetic ratio}, that is, the proportionality constant
between a particle’s angular momentum and magnetic moment. The constant $\mu_b = e\hbar / (2m_e c)$
is the Bohr magneton, the basic measure for magnetic moments.

\vspace{2mm}

\par Even for small numbers of particles, the $2^N$ possible spin configurations gets to be very
large ( $2^{20} > 10^6$ ), and it is expensive for the computer to examine them all. Realistic samples
with $\approx 10^{23}$ particles are beyond imagination. Consequently, statistical approaches are usually
assumed, even for moderate values of $N$.

\vspace{2mm}

\par The energy of the system in state $\alpha_k$ is the expectation value of the sum of the potential $V$
over the spins of the particles:

\vspace{2mm}

\begin{equation*}
    E_{\alpha_k} = \bra{\alpha_k}\sum_{i}V_i\ket{\alpha_k} = -J\sum_{i=1}^{N-1}s_i s_{i+1} - B\mu_{b}\sum_{i=1}^{N}s_i
\end{equation*}

\vspace{2mm}

\par If we turn off the external magnetic field there will be no preferred
direction in space and the average magnetization should vanish even though
energetically most adventageous state would be all spins aligned. To
resolution of the paradox is that the system is unstable at $B=0$. Some properties must be
calculated differently. For example magnetization should be calculated $\bra{}\sum_{i}s_{i}\ket{}$
and not $\langle \sum_{i}s_{i}\rangle$, with no preferred direction.

\vspace{2mm}

\par The equilibrium alignment of the spins depends critically on the sign of the exchange
energy $J$ . If $J > 0$ , the lowest energy state will tend to have neighboring spins aligned. If the
temperature is low enough, the ground state will be a ferromagnet with all the spins aligned.
If $J < 0$ , the lowest energy state will tend to have neighbors with opposite spins. If the
temperature is low enough, the ground state will be a antiferromagnet with alternating spins.

\vspace{2mm}

\par A fascinating aspect of magnetic materials is the existence of a critical temperature, the
\textit{Curie temperature}, above which the gross magnetization essentially vanishes. Below the Curie
temperature the quantum state of the material has long-range order extending over macroscopic
dimensions; above the Curie temperature there is only short-range order extending over atomic
dimensions. Even though the 1-D Ising model predicts realistic temperature dependences for
the thermodynamic quantities, the model is too simple to support a phase transition. However,
the 2-D and 3-D Ising models do support the Curie temperature phase transition.

\vspace{2mm}

\section{Some statistical mechanics}

\vspace{2mm}

\par Statistical mechanics starts with the elementary interactions among a system’s particles and
constructs the macroscopic thermodynamic properties such as specific heats. The essential
assumption is that all configurations of the system consistent with the constraints are possible.
In some simulations the problem is set up such that the energy of the system is fixed.
The states of this type of system are described by what is called a \textit{microcanonical ensemble}. In
contrast, when the temperature, volume,
and number of particles remain fixed, we have what is called a \textit{canonical ensemble}.

\vspace{2mm}

\par When we say that an object is at temperature $T$ , we mean that the object’s atoms are
in thermodynamic equilibrium at temperature $T$ such that each atom has an average energy
proportional to $T$ . Although this may be an equilibrium state, it is a dynamic one in which the
object’s energy fluctuates as it exchanges energy with its environment (it is thermodynamics
after all). Indeed, one of the most illuminating aspects of the simulation we shall develop is its
visualization of the continual and random interchange of energy that occurs at equilibrium.

\vspace{2mm}

\par The energy $E_{\alpha_j}$ of state $\alpha_j$ in a canonical ensemble is not constant but is distributed with
probabilities $P(\alpha_j)$ given by the Boltzmann distribution:

\vspace{2mm}

\begin{equation*}
    P(E_{\alpha_j}, T) = \frac{e^{-E_{\alpha_j} / k_B T}}{Z(T)}
\end{equation*}

\vspace{2mm}

\begin{equation*}
    Z(T) = \sum_{\alpha_j} e^{-E_{\alpha_j}} / k_B T
\end{equation*}

\vspace{2mm}

\par Here $k$ is Boltzmann’s constant, $T$ is the temperature, and $Z(T)$ is the partition function,
a weighted sum over states. Note that the sums $Z(T)$ are over the individual states or
configurations of the system. Another formulation is to sum over the energies of the states of the system and includes a density-of-states
factor $g(E_i)$ to account for degenerate states with the same energy. While the present sum over
states is a simpler way to express the problem (one less function), we shall see that the sum
over energies is more efficient numerically. In fact, in this section we even ignore the partition
function $Z(T)$ because it cancels out when dealing with the ratio of probabilities.

\vspace{2mm}



\bibliographystyle{plain}
\bibliography{references}

\end{document}
